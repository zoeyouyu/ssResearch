---
title: "Main.new"
author: "Zoe Zhou"
date: "18/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

----------------------------------------  NOTES ------------------------------------------------------
Pressure values are records at a frequency of 50 Hz. 
So 50 measurements per second. 
1 measurement every 20 milliseconds. 


-------------------------------------------------------------------------------------------------------

Special case:
- Sometimes for iPhone 7 (One of Jackie's devices):

Pressure values are records at a frequency of 40 Hz. 
So 40 measurements per second. 
1 measurement every 25 milliseconds. 
-------------------------------------------------------------------------------------------------------


# Process all folders (maybe)
```{r}
# Load in all the helper functions
source("Functions.R")

# Find folders that contain our data - you can feed in the folder names manually here e.g. data.folders = ...
all.folders = list.dirs(path = getwd(), recursive = FALSE)
data.folders = find.data.folders(all.folders)
```


# Process one folder
```{r}
folder = data.folders[5]
df.list = get.df.list(folder)
```

## Step 1. Have an overall peek at our data
##### One of them maybe ambient data - usually df1 - need to be decided manually. Sometimes data might be broken due to the Bluetooth connection lost.

##### Check temperature
```{r}
lapply(df.list, plot.temp)
```

##### Check Pressure
```{r}
lapply(df.list, myplot)
```

### If not broken, often Jenny's data. Just choose the good df as the whole.
#### Pass the whole recording data (manual selection)// or we can check the sizes of all list elements (pass the largest df)
```{r}
#whole = df.list[[2]]
```

### If broken, often Jackie's data. We need to combine them back together.
#### Mutate new column rectime (recording time) to combine all data frames (except the ambient data - usually df1). Note the *timegap* here is 20 ms. See notes at the top.
```{r}
(whole = combinedf(df.list, timegap = 20))
```

#### Putting Pressure and temperature side by side and have a look
```{r}
side.by.side(pressuredata = whole, tempdata = whole, name = "the whole recording")
```

#### Make some comments here


## Step 2. Remove baseline.
##### Default - take the first 3 seconds' data (we consider it as the relax period) - can manually change to 2 seconds or 5 seconds
```{r}
first3seconds = whole %>% filter(rectime < 3000)

# Look at this first 3 seconds - if abnormal choose another period
plot2(first3seconds, name = "first 3 seconds")
```

#### After removal, take a look at the whole recording with temperature
```{r}
# our dataset called `change` now (since after removal, we have the pressure change for each sensor)
change = baseline(whole, first3seconds)

side.by.side(pressuredata = change, tempdata = whole, name = "the whole recording (baseline removed)")

# Save this image to impress your supervisors xD
#ggsave("Whole (with temp).png", width = 10, height = 5)
```

## Step 3. Cut the whole to get Squeeze and Hold (optional).
##### Sometimes need to manually subtract a few seconds before next exercise starts (to get just `Squeeze and hold` data) - e.g. here we subtract another 75 s
Due to the Bluetooth connection lost, we lost some time.
But when we are combining all dfs back together, we mutate a new `rectime` column, which is continuous. If we can come up with a better approach to deal with this lost time, we might not need to manually subtract extra seconds. 



```{r}
exercise.info(folder)

# Get json time when `Squeeze and hold` starts and when does it end (the next exercise starts)
exercise_start_time = as.numeric(getjsontime(folder)[1])

next_start_time = as.numeric(getjsontime(folder)[2])

# Subset pressuredata and tempdata
# Check if you successfully subset this
change %>% filter(rectime < (next_start_time - exercise_start_time - 75000)) %>% 
   plot2(name = "Squeeze and hold")
```


```{r}
pressuredata = change %>% filter(rectime < (next_start_time - exercise_start_time - 75000))
tempdata = whole %>% filter(rectime < (next_start_time - exercise_start_time - 75000))

side.by.side(pressuredata, tempdata, name = "Squeeze and hold")

# Save this image to impress your supervisors again xD
#ggsave("Squeeze and hold (with temp).png", width = 10, height = 5)
```

#### Comments
The negative values in the graph above were resulted from the sensors. It doesn't mean we removed baseline values wrongly.
When the sensors were being contracted  by the muscles around, they were being sucked, and might be stuck for a bit. 
After contraction, the muscle relaxed (during the resting time), the sensors were trying to go back to its original place *slowly.* Hence we observe not always just a flat line, instead some of the sensors *slowly* jumped back from negative to 0.



## Step 4. Prepare for segmentation.
#### Method 
Each contraction in the `Squeeze and Hold` exercise is very interesting, here we are going to zoom in and give PFMCs (Pelvic Floor Muscle Contractions) a closeup check.

To achieve this, we have to get the exact starting/ending time for each contraction. We need help from some magical algorithms. There is a variety of options available including PCA (Principle Component Analysis), Changepoints detection, Gradient check, Peak detection, Classification tree and cross-validation model (fancy machine learning approach - talk to David Chen if interested, his model was very impressive but I'm too dumb(lazy) to recreate that). After trying different methods, I decided to use Smoothing and changepoints detection. 

For some `well-behaved` pressure traces, we can use the *peak pressure trace* to represent the overall pattern of the trace. 

##### If good - Peak pressure trace?
```{r}
# Not interested in the temperature from now on, only take column p1-p8 
change$peak = apply(change[, paste0("p", 1:8)], 1, max)

# Can Pass the subset as data frame when we are happy with the cutting in step 3
# squeeze_and_hold = change %>% filter(rectime < (next_start_time - squeeze_and_hold_start_time))

# Emphasize the peaks
plot2(change) + geom_line(aes(x = rectime, y = peak), col = "black")
```


But sometimes the data is very noisy due to the great sensitivity of the femfit sensors, then we need smoothing (Local Polynomial Regression Fitting) to smooth out the noise, which reduce the variance a lot, but still capturing the patterns of the traces.


##### If noisy - Can we smooth the peak pressure values? `span` is really important here
```{r}
tidydata = tidy.pressure(change)
smoothed.peak.df = get.smooth.line(tidydata)
```

## Step 4.5. Detect peaks (optional - it picks up small peaks sometimes so it's a bit useless)


Default minpeakdistance = 500 (each contraction last around 5s).
This really depends on the participant (time length of contractions varies! Sometimes 7s, 8s, or 10s)

##### Get the top n peaks. 
```{r}
n_peaks = get.peaks(change, smoothed.peak.df, timelength = 5000, minpeakdistance = 500)
```

## Step 5. Segmentation
##### Using changepoints detection. I call it Greedy method, since we are tying to get  `n_peaks*2` at one go using Binary Segmentation
Here we can always feed in n_peaks = 20, so step 4.5 is sometimes useless, if we know 20 contractions happened), Q = 40. 
Need to manually change Q here to give the best results. 
Need to always check on the plot before running! Sometimes unnoticeable small red line (a changepoint) occurs.

```{r}
greedy.fit = get.greedy.fit(smoothed.peak.df, n_peaks)
```


#### Comments
Usually doing pretty well (catch the changes) for `Squeeze and Hold`, sometimes very good for the `Rapids` as well. But not very great for Endurance exercise and the Knacks. Since they have different patterns of pressure traces. The endurance has 2 jumps, one halfway, one maximum contraction. The knack is a combination of contraction and cough, so somewhat complex for the algorithm to identify. 

In that case we can just throw out the last few points (endurance and knacks) for now.

Sometimes we have messy data (always), the participants might have done something strange at the beginning of the exercise, so we can throw that away too.

## Step 6. Plot
```{r}
# Let's ignore the endurance and the knack for now (the last 8 changepoints excluded)
mypoints = drop.points(greedy.fit, dropfirst = 4, droplast = 8)

# Check how it looks like without shifting
how.to.shift(change, mypoints, n_event = 20)
```

##### Decided to shift starting time of everything (except no.14) 30 points to the left, the ending time of no.14 30 points to the right
```{r}
how.to.shift(change, mypoints, n_event = 20,
             start.go.left = -14, start.go.left.size = 30,
             end.go.right = 14, end.go.right.size = 30)
```


##### Just double check if we actually get the changepoints right
```{r}
# plot2(change) + theme_void() + 
#   geom_vline(xintercept = start.end.rectime)
```

##### Now they should look perfect and ready to be saved
```{r}
how.to.shift(change, mypoints, n_event = 20, save = TRUE,
             start.go.left = -14, start.go.left.size = 30,
             end.go.right = 14, end.go.right.size = 30)

```

## Step 6. Average out
We want to look at how the pressure values change over contractions, now we are going to take the mean pressure value within each contraction, for each sensor, then plot the mean values over 20 contractions. 

Sometimes during the exercise, the femfit slips a bit, the position change occurs. From this graph, we can have a good idea which sensors are contributing the most and how does the shift happen (if it happens).
```{r}
contraction.df = get.contraction.df(change, mypoints)
get.averaged.plot(contraction.df)
```












